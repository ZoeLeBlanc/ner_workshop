{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Custom NER Models\n",
    "\n",
    "Today's Goals/Agenda:\n",
    "- Review Wednesday materials and our deeper diver into spaCy\n",
    "- Building and training custom NER models\n",
    "- Discussion of how we build training data\n",
    "\n",
    "Final afternoon of TAPI and NER workshop 🥳😳!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download Spacy in Binder\n",
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download Spacy if running locally\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install spacy\n",
    "# !{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.scorer import Scorer\n",
    "from spacy.training import Example\n",
    "import stanza\n",
    "import spacy_stanza\n",
    "import numpy as np\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's some of our original code from Monday "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our data\n",
    "chars_df = pd.read_csv('./archive/Characters.csv', delimiter=';')\n",
    "chars_df['split_names'] = chars_df.Name.str.split(' ')\n",
    "film1_df = pd.read_csv('./archive/Harry Potter 1.csv', delimiter=';')\n",
    "\n",
    "def find_entities(row):\n",
    "    # Find character names from chars_df\n",
    "    character_names = chars_df.split_names.tolist()\n",
    "    identified_names = []\n",
    "    for names in character_names:\n",
    "        if any(name in row.Sentence for name in names):\n",
    "            identified_names.append(' '.join(names))\n",
    "    row['identified_names'] = identified_names\n",
    "    return row\n",
    "\n",
    "film1_entities = film1_df.apply(find_entities, axis=1)\n",
    "film1_entities = film1_entities[film1_entities.identified_names.astype(bool)]\n",
    "film1_exploded = film1_entities.explode('identified_names')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of our code from Wednesday 👇🏽"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example rule {'label': 'PERSON', 'pattern': [{'LOWER': 'parvati'}], 'id': 'parvati'}\n",
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': 1.0, 'sents_r': 1.0, 'sents_f': 1.0, 'tag_acc': None, 'pos_acc': None, 'morph_acc': None, 'morph_per_feat': None, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'PERSON': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'CARDINAL': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'TIME': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'ORDINAL': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NORP': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'QUANTITY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'cats_score': 0.0, 'cats_score_desc': 'macro F', 'cats_micro_p': 0.0, 'cats_micro_r': 0.0, 'cats_micro_f': 0.0, 'cats_macro_p': 0.0, 'cats_macro_r': 0.0, 'cats_macro_f': 0.0, 'cats_macro_auc': 0.0, 'cats_f_per_type': {}, 'cats_auc_per_type': {}}\n"
     ]
    }
   ],
   "source": [
    "# Load film datasets\n",
    "film1_df = pd.read_csv('./archive/Harry Potter 1.csv', delimiter=';')\n",
    "film2_df = pd.read_csv('./archive/Harry Potter 2.csv', delimiter=';')\n",
    "film3_df = pd.read_csv('./archive/Harry Potter 3.csv', delimiter=';')\n",
    "\n",
    "# Combine film dataframes\n",
    "film3_df.columns = map(str.capitalize, film3_df.columns)\n",
    "film1_df['movie_number'] = 'film 1'\n",
    "film2_df['movie_number'] = 'film 2'\n",
    "film3_df['movie_number'] = 'film 3'\n",
    "films_df = pd.concat([film1_df, film2_df, film3_df])\n",
    "\n",
    "chars_df['full_names'] = np.where(\n",
    "    chars_df.split_names.str.len() == 2, \n",
    "    chars_df.split_names.str[0].str.lower() + ' ' + chars_df.split_names.str[1].str.lower(), \n",
    "    np.where(\n",
    "        chars_df.split_names.str.len() > 2,\n",
    "        chars_df.split_names.str[0].str.lower() + ' ' + chars_df.split_names.str[-1].str.lower(),\n",
    "        chars_df.split_names.str[0].str.lower())) \n",
    "chars_df['first_name'] = chars_df.split_names.str[0].str.lower()\n",
    "chars_df['last_name'] = chars_df.split_names.str[-1].str.lower()\n",
    "\n",
    "full_names = chars_df.full_names.unique().tolist()\n",
    "first_names = chars_df.first_name.unique().tolist()\n",
    "last_names = chars_df.last_name.unique().tolist()\n",
    "\n",
    "# Get unique names and create our rules\n",
    "names = list(set(first_names) | set(last_names))\n",
    "unique_names = list(set(names) | set(full_names))\n",
    "list_names = [{\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": f\"{name}\"}], \"id\": f\"{name}\"} for name in unique_names if len(name.split(' ')) == 1]\n",
    "\n",
    "list_full_names = [{\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": f\"{name.split(' ')[0]}\"}, {\"LOWER\": f\"{name.split(' ')[1]}\"}], \"id\": f\"{'-'.join(name.split(' '))}\"} for name in full_names if len(name.split(' ')) > 1]\n",
    "\n",
    "all_names = list_names + list_full_names\n",
    "print('example rule', all_names[0])\n",
    "\n",
    "# Load our models and pass our rules\n",
    "full_nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = full_nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(all_names)\n",
    "\n",
    "blank_nlp = spacy.blank(\"en\")\n",
    "ruler = blank_nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(all_names)\n",
    "\n",
    "evaluation_data = []\n",
    "def evaluate_spacy_models(row):\n",
    "    # Let's also add in blank_nlp\n",
    "    sentences = nltk.sent_tokenize(row.Sentence.lower())\n",
    "    for sentence in sentences:\n",
    "        spacy_full = full_nlp(sentence)\n",
    "        list_entities = []\n",
    "        for token in spacy_full.ents:\n",
    "            list_entities.append([token.start_char, token.end_char, token.label_])\n",
    "        if len(list_entities) > 0:\n",
    "            entry = (sentence,{\"entities\": list_entities})\n",
    "            evaluation_data.append(entry)\n",
    "    return row\n",
    "films_df.apply(evaluate_spacy_models, axis=1)\n",
    "\n",
    "def evaluate(ner_model, testing_data):\n",
    "    scorer = Scorer()\n",
    "    examples = []\n",
    "    for input_, annot in testing_data:\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        example = Example.from_dict(doc_gold_text, annot)\n",
    "        example.predicted = ner_model(input_)\n",
    "        examples.append(example)\n",
    "        \n",
    "    print(scorer.score(examples))\n",
    "\n",
    "# print the results\n",
    "evaluate(full_nlp, evaluation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank Harry Potter PERSON\n",
      "blank Harry PERSON\n",
      "blank Weasley PERSON\n",
      "blank Tom PERSON\n",
      "blank Riddle PERSON\n",
      "blank Tom Riddle PERSON\n",
      "blank Gilderoy Lockhart PERSON\n",
      "blank Harry PERSON\n",
      "blank Harry PERSON\n",
      "blank Hermione PERSON\n",
      "blank Harry PERSON\n",
      "blank Harry PERSON\n",
      "blank Lucius Malfoy PERSON\n",
      "blank Draco PERSON\n",
      "full Harry Potter PERSON\n",
      "full the Chamber of Secrets ORG\n",
      "full Harry PERSON\n",
      "full second year DATE\n",
      "full Hogwarts ORG\n",
      "full 50-year-old DATE\n",
      "full Ron PERSON\n",
      "full Ginny Weasley PERSON\n",
      "full her first year DATE\n",
      "full Hogwarts ORG\n",
      "full Tom Marvolo Riddle PERSON\n",
      "full World War II EVENT\n",
      "full Voldemort ORG\n",
      "full Tom Riddle PERSON\n",
      "full Ginny PERSON\n",
      "full Voldemort ORG\n",
      "full Ginny ORG\n",
      "full Voldemort ORG\n",
      "full Hogwarts PRODUCT\n",
      "full Defence Against the Dark Arts ORG\n",
      "full Gilderoy Lockhart PERSON\n",
      "full Harry PERSON\n",
      "full the Wizarding World LOC\n",
      "full Voldemort PERSON\n",
      "full Muggles PERSON\n",
      "full Harry PERSON\n",
      "full the Dark Arts ORG\n",
      "full Hermione PERSON\n",
      "full Harry PERSON\n",
      "full Ron PERSON\n",
      "full the Chamber of Secrets ORG\n",
      "full Harry PERSON\n",
      "full Ginny PERSON\n",
      "full Voldemort ORG\n",
      "full Lucius Malfoy PERSON\n",
      "full Draco ORG\n",
      "full Ron PERSON\n",
      "full Ginny PERSON\n",
      "full Ginny PERSON\n"
     ]
    }
   ],
   "source": [
    "# How we can test our models\n",
    "# https://en.wikipedia.org/wiki/Harry_Potter\n",
    "test_text = \"The series continues with Harry Potter and the Chamber of Secrets, describing Harry's second year at Hogwarts. He and his friends investigate a 50-year-old mystery that appears uncannily related to recent sinister events at the school. Ron's younger sister, Ginny Weasley, enrols in her first year at Hogwarts, and finds an old notebook in her belongings which turns out to be the diary of a previous student, Tom Marvolo Riddle, written during World War II. He is later revealed to be Voldemort's younger self, who is bent on ridding the school of 'mudbloods', a derogatory term describing wizards and witches of non-magical parentage. The memory of Tom Riddle resides inside of the diary and when Ginny begins to confide in the diary, Voldemort is able to possess her. Through the diary, Ginny acts on Voldemort's orders and unconsciously opens the 'Chamber of Secrets', unleashing an ancient monster, later revealed to be a basilisk, which begins attacking students at Hogwarts. It kills those who make direct eye contact with it and petrifies those who look at it indirectly. The book also introduces a new Defence Against the Dark Arts teacher, Gilderoy Lockhart, a highly cheerful, self-conceited wizard with a pretentious facade, later turning out to be a fraud. Harry discovers that prejudice exists in the Wizarding World through delving into the school's history, and learns that Voldemort's reign of terror was often directed at wizards and witches who were descended from Muggles. Harry also learns that his ability to speak the snake language Parseltongue is rare and often associated with the Dark Arts. When Hermione is attacked and petrified, Harry and Ron finally piece together the puzzles and unlock the Chamber of Secrets, with Harry destroying the diary for good and saving Ginny, and, as they learn later, also destroying a part of Voldemort's soul. The end of the book reveals Lucius Malfoy, Draco's father and rival of Ron and Ginny's father, to be the culprit who slipped the book into Ginny's belongings.\"\n",
    "\n",
    "doc = blank_nlp(test_text)\n",
    "for token in doc.ents:\n",
    "    print('blank', token.text, token.label_)\n",
    "\n",
    "doc = full_nlp(test_text)\n",
    "for token in doc.ents:\n",
    "    print('full', token.text, token.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And then save our models to disk. You can read more here https://spacy.io/usage/saving-loading\n",
    "blank_nlp.to_disk('blank_nlp')\n",
    "full_nlp.to_disk('full_nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Training a Custom NER Model\n",
    "\n",
    "Two ways you can train.\n",
    "Either:\n",
    "1. Train a completely blank model\n",
    "2. Finetune a pretrained model\n",
    "\n",
    "Today we're going to try both options and discuss the tradeoffs.\n",
    "\n",
    "On Wednesday we were trying to build our training data, but it turns out there was a bit of a problem with the approach I attempted. Let's try it out and see why it didn't work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a reminder our goal was to take our spells dataset and use it to create a new entity label, named `SPELL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Incantation</th>\n",
       "      <th>Type</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summoning Charm</td>\n",
       "      <td>Accio</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Summons an object</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age Line</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Prevents people above or below a certain age f...</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Incantation   Type  \\\n",
       "0  Summoning Charm       Accio  Charm   \n",
       "1         Age Line     Unknown  Charm   \n",
       "\n",
       "                                              Effect Light  \n",
       "0                                  Summons an object  None  \n",
       "1  Prevents people above or below a certain age f...  Blue  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spells_df = pd.read_csv('./archive/Spells.csv', sep=\";\")\n",
    "spells_df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check that spells exist in our films dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spells(row):\n",
    "    spells = spells_df[spells_df.Incantation.isna() == False].Incantation.unique().tolist()\n",
    "    identified_spells = []\n",
    "    for spell in spells:\n",
    "        if spell in row.Sentence:\n",
    "            identified_spells.append(spell)\n",
    "    row['identified_spells'] = ', '.join(identified_spells) if len(identified_spells) > 0 else ''\n",
    "    return row\n",
    "films_spells = films_df.apply(find_spells, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>identified_spells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Oculus Reparo.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Oculus Reparo, Reparo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Alohomora</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Alohomora?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Flitwick</td>\n",
       "      <td>Wingardium Leviosa.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Wingardium Leviosa.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Wingardium Leviosa!</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Petrificus Totalus.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Petrificus Totalus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Alohomora.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Alohomora!</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Oculus Reparo.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Oculus Reparo, Reparo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>GILDEROY LOCKHART</td>\n",
       "      <td>Peskipiksi Pesternomi!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Peskipiksi Pesternomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Immobulus!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Immobulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MCGONAGALL</td>\n",
       "      <td>One, two, three. Vera Verto.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vera Verto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>MCGONAGALL</td>\n",
       "      <td>One, two, three. Vera Verto.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vera Verto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>RON</td>\n",
       "      <td>Vera Verto!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vera Verto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Finite Incantatem!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Finite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>GILDEROY LOCKHART</td>\n",
       "      <td>Brackium Emendo!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Brackium Emendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>SNAPE</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>DRACO</td>\n",
       "      <td>Everte Statum!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Everte Statum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Rictusempra!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Rictusempra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>DRACO</td>\n",
       "      <td>Serpensortia!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Serpensortia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>GILDEROY LOCKHART</td>\n",
       "      <td>Alarte Ascendare!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Alarte Ascendare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>SNAPE</td>\n",
       "      <td>Vipera Evanesca.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vipera Evanesca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Wingardium Leviosa.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>TOM RIDDLE</td>\n",
       "      <td>Cistem Aperio!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Cistem Aperio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>TOM RIDDLE</td>\n",
       "      <td>Arania Exumai!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Arania Exumai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Arania Exumai!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Arania Exumai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Arania Exumai!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Arania Exumai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos Maxima...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos, Lumos Maxima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos Maxima...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos, Lumos Maxima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos Maxima...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos, Lumos Maxima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos... MAXIMA!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>After me. Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>CLASS</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Listen: Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>CLASS</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>NEVILLE</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>RON</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>PARVATI</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Then speak the incantation, Expecto Patronum.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Mischief managed. Nox.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Nox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>SNAPE</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Immobulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Immobulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Bombarda!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Bombarda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>None of it made any difference.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Nox.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Nox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Character                                       Sentence  \\\n",
       "430            Hermione                                 Oculus Reparo.   \n",
       "720            Hermione                                      Alohomora   \n",
       "722                 Ron                                     Alohomora?   \n",
       "776            Flitwick                           Wingardium Leviosa.    \n",
       "786            Hermione                            Wingardium Leviosa.   \n",
       "831               Ron                             Wingardium Leviosa!    \n",
       "1324          Hermione                             Petrificus Totalus.   \n",
       "1332         Hermione                                       Alohomora.   \n",
       "1391             Ron                                       Alohomora!    \n",
       "266            HERMIONE                                 Oculus Reparo.   \n",
       "481   GILDEROY LOCKHART                         Peskipiksi Pesternomi!   \n",
       "484            HERMIONE                                     Immobulus!   \n",
       "646          MCGONAGALL                   One, two, three. Vera Verto.   \n",
       "650          MCGONAGALL                   One, two, three. Vera Verto.   \n",
       "651                 RON                                    Vera Verto!   \n",
       "735            HERMIONE                             Finite Incantatem!   \n",
       "744   GILDEROY LOCKHART                               Brackium Emendo!   \n",
       "846               SNAPE                                  Expelliarmus!   \n",
       "868               DRACO                                 Everte Statum!   \n",
       "869               HARRY                                   Rictusempra!   \n",
       "871               DRACO                                  Serpensortia!   \n",
       "875   GILDEROY LOCKHART                              Alarte Ascendare!   \n",
       "876               SNAPE                               Vipera Evanesca.   \n",
       "973               HARRY                            Wingardium Leviosa.   \n",
       "1120         TOM RIDDLE                                 Cistem Aperio!   \n",
       "1121         TOM RIDDLE                                 Arania Exumai!   \n",
       "1310              HARRY                                 Arania Exumai!   \n",
       "1313              HARRY                                 Arania Exumai!   \n",
       "0                 HARRY                                Lumos Maxima...   \n",
       "1                 HARRY                                Lumos Maxima...   \n",
       "2                 HARRY                                Lumos Maxima...   \n",
       "3                 HARRY                               Lumos... MAXIMA!   \n",
       "505               LUPIN                          After me. Riddikulus!   \n",
       "506               CLASS                                    Riddikulus!   \n",
       "509               LUPIN                            Listen: Riddikulus!   \n",
       "510               CLASS                                    Riddikulus!   \n",
       "538             NEVILLE                                    Riddikulus!   \n",
       "548                 RON                                    Riddikulus!   \n",
       "554             PARVATI                                    Riddikulus!   \n",
       "557               LUPIN                                    Riddikulus!   \n",
       "897               LUPIN  Then speak the incantation, Expecto Patronum.   \n",
       "898               HARRY                              Expecto Patronum.   \n",
       "901               HARRY                              Expecto Patronum!   \n",
       "925               HARRY                              Expecto Patronum!   \n",
       "926               HARRY                              Expecto Patronum!   \n",
       "982               HARRY                         Mischief managed. Nox.   \n",
       "1169              LUPIN                                  Expelliarmus!   \n",
       "1205              SNAPE                                  Expelliarmus!   \n",
       "1228              HARRY                                  Expelliarmus!   \n",
       "1332              HARRY                                  Expelliarmus!   \n",
       "1346              HARRY                              Expecto Patronum!   \n",
       "1504              LUPIN                                     Immobulus!   \n",
       "1554              HARRY                              Expecto Patronum!   \n",
       "1561           HERMIONE                                      Bombarda!   \n",
       "1601              HARRY                None of it made any difference.   \n",
       "1634              HARRY                                         Lumos.   \n",
       "1637              HARRY                                           Nox.   \n",
       "\n",
       "     movie_number      identified_spells  \n",
       "430        film 1  Oculus Reparo, Reparo  \n",
       "720        film 1              Alohomora  \n",
       "722        film 1              Alohomora  \n",
       "776        film 1     Wingardium Leviosa  \n",
       "786        film 1     Wingardium Leviosa  \n",
       "831        film 1     Wingardium Leviosa  \n",
       "1324       film 1     Petrificus Totalus  \n",
       "1332       film 1              Alohomora  \n",
       "1391       film 1              Alohomora  \n",
       "266        film 2  Oculus Reparo, Reparo  \n",
       "481        film 2  Peskipiksi Pesternomi  \n",
       "484        film 2              Immobulus  \n",
       "646        film 2             Vera Verto  \n",
       "650        film 2             Vera Verto  \n",
       "651        film 2             Vera Verto  \n",
       "735        film 2                 Finite  \n",
       "744        film 2        Brackium Emendo  \n",
       "846        film 2           Expelliarmus  \n",
       "868        film 2          Everte Statum  \n",
       "869        film 2            Rictusempra  \n",
       "871        film 2           Serpensortia  \n",
       "875        film 2       Alarte Ascendare  \n",
       "876        film 2        Vipera Evanesca  \n",
       "973        film 2     Wingardium Leviosa  \n",
       "1120       film 2          Cistem Aperio  \n",
       "1121       film 2          Arania Exumai  \n",
       "1310       film 2          Arania Exumai  \n",
       "1313       film 2          Arania Exumai  \n",
       "0          film 3    Lumos, Lumos Maxima  \n",
       "1          film 3    Lumos, Lumos Maxima  \n",
       "2          film 3    Lumos, Lumos Maxima  \n",
       "3          film 3                  Lumos  \n",
       "505        film 3             Riddikulus  \n",
       "506        film 3             Riddikulus  \n",
       "509        film 3             Riddikulus  \n",
       "510        film 3             Riddikulus  \n",
       "538        film 3             Riddikulus  \n",
       "548        film 3             Riddikulus  \n",
       "554        film 3             Riddikulus  \n",
       "557        film 3             Riddikulus  \n",
       "897        film 3       Expecto Patronum  \n",
       "898        film 3       Expecto Patronum  \n",
       "901        film 3       Expecto Patronum  \n",
       "925        film 3       Expecto Patronum  \n",
       "926        film 3       Expecto Patronum  \n",
       "982        film 3                    Nox  \n",
       "1169       film 3           Expelliarmus  \n",
       "1205       film 3           Expelliarmus  \n",
       "1228       film 3           Expelliarmus  \n",
       "1332       film 3           Expelliarmus  \n",
       "1346       film 3       Expecto Patronum  \n",
       "1504       film 3              Immobulus  \n",
       "1554       film 3       Expecto Patronum  \n",
       "1561       film 3               Bombarda  \n",
       "1601       film 3                   None  \n",
       "1634       film 3                  Lumos  \n",
       "1637       film 3                    Nox  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films_spells[films_spells.identified_spells.str.len() > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here's where we left off on Wednesday... \n",
    "\n",
    "To build training data, we can do a few different approaches. Initially, I was hoping to have us use a similar approach to our `PERSON` example.\n",
    "\n",
    "If you remember, we figured out how to extract character names and then created spaCy rules and fed them into both a pre-trained and blank model.\n",
    "\n",
    "```python\n",
    "chars_df['full_names'] = np.where(\n",
    "    chars_df.split_names.str.len() == 2, \n",
    "    chars_df.split_names.str[0].str.lower() + ' ' + chars_df.split_names.str[1].str.lower(), \n",
    "    np.where(\n",
    "        chars_df.split_names.str.len() > 2,\n",
    "        chars_df.split_names.str[0].str.lower() + ' ' + chars_df.split_names.str[-1].str.lower(),\n",
    "        chars_df.split_names.str[0].str.lower())) \n",
    "\n",
    "full_names = chars_df.full_names.unique().tolist()\n",
    "first_names = chars_df.first_name.unique().tolist()\n",
    "last_names = chars_df.last_name.unique().tolist()\n",
    "\n",
    "names = list(set(first_names) | set(last_names))\n",
    "unique_names = list(set(names) | set(full_names))\n",
    "list_names = [{\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": f\"{name}\"}], \"id\": f\"{name}\"} for name in unique_names if len(name.split(' ')) == 1]\n",
    "\n",
    "list_full_names = [{\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": f\"{name.split(' ')[0]}\"}, {\"LOWER\": f\"{name.split(' ')[1]}\"}], \"id\": f\"{'-'.join(name.split(' '))}\"} for name in full_names if len(name.split(' ')) > 1]\n",
    "\n",
    "all_names = list_names + list_full_names\n",
    "print('example rule', all_names[0])\n",
    "\n",
    "# Load our models and pass our rules\n",
    "full_nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = full_nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(all_names)\n",
    "\n",
    "blank_nlp = spacy.blank(\"en\")\n",
    "ruler = blank_nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(all_names)\n",
    "```\n",
    "So let's try and replicate this with our spells data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we needed to extract our spells from spells_df. I've written one way to do that below but right now it is splitting our spells apart so that we feed in `Wingardium` and `Leviosa` as separate tokens. On Wednesday we decided that didn't make sense, so let's tweak this code to only create rules with the full spell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'SPELL', 'pattern': [{'LOWER': 'accio'}], 'id': 'Accio'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spells_df.Incantation = spells_df.Incantation.fillna(\"\")\n",
    "spells = spells_df.Incantation.unique().tolist()\n",
    "spells = [spell for spell in spells if len(spell) > 1]\n",
    "list_spells = []\n",
    "for spell in spells:\n",
    "    split_spells = spell.split()\n",
    "    patterns = []\n",
    "    for sp in split_spells:\n",
    "        patterns.append({\"LOWER\": f\"{sp.lower()}\"})\n",
    "    spell_dict = {\"label\": \"SPELL\", \"pattern\": patterns, \"id\": f\"{'-'.join(spell.split())}\"}\n",
    "    list_spells.append(spell_dict)\n",
    "list_spells[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our rules let's try passing them into a blank model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "spell_nlp = spacy.blank('en')\n",
    "ruler = spell_nlp.add_pipe(\"entity_ruler\") \n",
    "ruler.add_patterns(list_spells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like this worked! (*slight detour into storytime for why one small error broke my code on Wednesday*). https://spacy.io/usage/rule-based-matching\n",
    "\n",
    "Next step is testing that our model is working. Let's try passing it some text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oculus Reparo SPELL\n"
     ]
    }
   ],
   "source": [
    "test_doc = spell_nlp(films_spells[films_spells.identified_spells.str.len() > 1].Sentence.values[0])\n",
    "for ent in test_doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright so let's build a function for generating our training data. I have a small function below, but let's tweak it a bit so that we can pass in any dataframe and model, and get our list of training data returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>identified_spells</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Oculus Reparo.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Oculus Reparo, Reparo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Alohomora</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Alohomora?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>Flitwick</td>\n",
       "      <td>Wingardium Leviosa.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Wingardium Leviosa.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>831</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Wingardium Leviosa!</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1324</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Petrificus Totalus.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Petrificus Totalus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>Hermione</td>\n",
       "      <td>Alohomora.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1391</th>\n",
       "      <td>Ron</td>\n",
       "      <td>Alohomora!</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Alohomora</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Oculus Reparo.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Oculus Reparo, Reparo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>GILDEROY LOCKHART</td>\n",
       "      <td>Peskipiksi Pesternomi!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Peskipiksi Pesternomi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Immobulus!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Immobulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>MCGONAGALL</td>\n",
       "      <td>One, two, three. Vera Verto.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vera Verto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>MCGONAGALL</td>\n",
       "      <td>One, two, three. Vera Verto.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vera Verto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>651</th>\n",
       "      <td>RON</td>\n",
       "      <td>Vera Verto!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vera Verto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Finite Incantatem!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Finite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>GILDEROY LOCKHART</td>\n",
       "      <td>Brackium Emendo!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Brackium Emendo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>SNAPE</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>DRACO</td>\n",
       "      <td>Everte Statum!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Everte Statum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Rictusempra!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Rictusempra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>DRACO</td>\n",
       "      <td>Serpensortia!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Serpensortia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>GILDEROY LOCKHART</td>\n",
       "      <td>Alarte Ascendare!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Alarte Ascendare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>SNAPE</td>\n",
       "      <td>Vipera Evanesca.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Vipera Evanesca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Wingardium Leviosa.</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Wingardium Leviosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1120</th>\n",
       "      <td>TOM RIDDLE</td>\n",
       "      <td>Cistem Aperio!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Cistem Aperio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>TOM RIDDLE</td>\n",
       "      <td>Arania Exumai!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Arania Exumai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Arania Exumai!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Arania Exumai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1313</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Arania Exumai!</td>\n",
       "      <td>film 2</td>\n",
       "      <td>Arania Exumai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos Maxima...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos, Lumos Maxima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos Maxima...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos, Lumos Maxima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos Maxima...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos, Lumos Maxima</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos... MAXIMA!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>After me. Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>CLASS</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Listen: Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>CLASS</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>NEVILLE</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>RON</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>PARVATI</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Riddikulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Riddikulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Then speak the incantation, Expecto Patronum.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Mischief managed. Nox.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Nox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1169</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205</th>\n",
       "      <td>SNAPE</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1332</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expelliarmus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expelliarmus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1346</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>LUPIN</td>\n",
       "      <td>Immobulus!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Immobulus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1554</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Expecto Patronum!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Expecto Patronum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1561</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Bombarda!</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Bombarda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>None of it made any difference.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Lumos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Nox.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Nox</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Character                                       Sentence  \\\n",
       "430            Hermione                                 Oculus Reparo.   \n",
       "720            Hermione                                      Alohomora   \n",
       "722                 Ron                                     Alohomora?   \n",
       "776            Flitwick                           Wingardium Leviosa.    \n",
       "786            Hermione                            Wingardium Leviosa.   \n",
       "831               Ron                             Wingardium Leviosa!    \n",
       "1324          Hermione                             Petrificus Totalus.   \n",
       "1332         Hermione                                       Alohomora.   \n",
       "1391             Ron                                       Alohomora!    \n",
       "266            HERMIONE                                 Oculus Reparo.   \n",
       "481   GILDEROY LOCKHART                         Peskipiksi Pesternomi!   \n",
       "484            HERMIONE                                     Immobulus!   \n",
       "646          MCGONAGALL                   One, two, three. Vera Verto.   \n",
       "650          MCGONAGALL                   One, two, three. Vera Verto.   \n",
       "651                 RON                                    Vera Verto!   \n",
       "735            HERMIONE                             Finite Incantatem!   \n",
       "744   GILDEROY LOCKHART                               Brackium Emendo!   \n",
       "846               SNAPE                                  Expelliarmus!   \n",
       "868               DRACO                                 Everte Statum!   \n",
       "869               HARRY                                   Rictusempra!   \n",
       "871               DRACO                                  Serpensortia!   \n",
       "875   GILDEROY LOCKHART                              Alarte Ascendare!   \n",
       "876               SNAPE                               Vipera Evanesca.   \n",
       "973               HARRY                            Wingardium Leviosa.   \n",
       "1120         TOM RIDDLE                                 Cistem Aperio!   \n",
       "1121         TOM RIDDLE                                 Arania Exumai!   \n",
       "1310              HARRY                                 Arania Exumai!   \n",
       "1313              HARRY                                 Arania Exumai!   \n",
       "0                 HARRY                                Lumos Maxima...   \n",
       "1                 HARRY                                Lumos Maxima...   \n",
       "2                 HARRY                                Lumos Maxima...   \n",
       "3                 HARRY                               Lumos... MAXIMA!   \n",
       "505               LUPIN                          After me. Riddikulus!   \n",
       "506               CLASS                                    Riddikulus!   \n",
       "509               LUPIN                            Listen: Riddikulus!   \n",
       "510               CLASS                                    Riddikulus!   \n",
       "538             NEVILLE                                    Riddikulus!   \n",
       "548                 RON                                    Riddikulus!   \n",
       "554             PARVATI                                    Riddikulus!   \n",
       "557               LUPIN                                    Riddikulus!   \n",
       "897               LUPIN  Then speak the incantation, Expecto Patronum.   \n",
       "898               HARRY                              Expecto Patronum.   \n",
       "901               HARRY                              Expecto Patronum!   \n",
       "925               HARRY                              Expecto Patronum!   \n",
       "926               HARRY                              Expecto Patronum!   \n",
       "982               HARRY                         Mischief managed. Nox.   \n",
       "1169              LUPIN                                  Expelliarmus!   \n",
       "1205              SNAPE                                  Expelliarmus!   \n",
       "1228              HARRY                                  Expelliarmus!   \n",
       "1332              HARRY                                  Expelliarmus!   \n",
       "1346              HARRY                              Expecto Patronum!   \n",
       "1504              LUPIN                                     Immobulus!   \n",
       "1554              HARRY                              Expecto Patronum!   \n",
       "1561           HERMIONE                                      Bombarda!   \n",
       "1601              HARRY                None of it made any difference.   \n",
       "1634              HARRY                                         Lumos.   \n",
       "1637              HARRY                                           Nox.   \n",
       "\n",
       "     movie_number      identified_spells  \n",
       "430        film 1  Oculus Reparo, Reparo  \n",
       "720        film 1              Alohomora  \n",
       "722        film 1              Alohomora  \n",
       "776        film 1     Wingardium Leviosa  \n",
       "786        film 1     Wingardium Leviosa  \n",
       "831        film 1     Wingardium Leviosa  \n",
       "1324       film 1     Petrificus Totalus  \n",
       "1332       film 1              Alohomora  \n",
       "1391       film 1              Alohomora  \n",
       "266        film 2  Oculus Reparo, Reparo  \n",
       "481        film 2  Peskipiksi Pesternomi  \n",
       "484        film 2              Immobulus  \n",
       "646        film 2             Vera Verto  \n",
       "650        film 2             Vera Verto  \n",
       "651        film 2             Vera Verto  \n",
       "735        film 2                 Finite  \n",
       "744        film 2        Brackium Emendo  \n",
       "846        film 2           Expelliarmus  \n",
       "868        film 2          Everte Statum  \n",
       "869        film 2            Rictusempra  \n",
       "871        film 2           Serpensortia  \n",
       "875        film 2       Alarte Ascendare  \n",
       "876        film 2        Vipera Evanesca  \n",
       "973        film 2     Wingardium Leviosa  \n",
       "1120       film 2          Cistem Aperio  \n",
       "1121       film 2          Arania Exumai  \n",
       "1310       film 2          Arania Exumai  \n",
       "1313       film 2          Arania Exumai  \n",
       "0          film 3    Lumos, Lumos Maxima  \n",
       "1          film 3    Lumos, Lumos Maxima  \n",
       "2          film 3    Lumos, Lumos Maxima  \n",
       "3          film 3                  Lumos  \n",
       "505        film 3             Riddikulus  \n",
       "506        film 3             Riddikulus  \n",
       "509        film 3             Riddikulus  \n",
       "510        film 3             Riddikulus  \n",
       "538        film 3             Riddikulus  \n",
       "548        film 3             Riddikulus  \n",
       "554        film 3             Riddikulus  \n",
       "557        film 3             Riddikulus  \n",
       "897        film 3       Expecto Patronum  \n",
       "898        film 3       Expecto Patronum  \n",
       "901        film 3       Expecto Patronum  \n",
       "925        film 3       Expecto Patronum  \n",
       "926        film 3       Expecto Patronum  \n",
       "982        film 3                    Nox  \n",
       "1169       film 3           Expelliarmus  \n",
       "1205       film 3           Expelliarmus  \n",
       "1228       film 3           Expelliarmus  \n",
       "1332       film 3           Expelliarmus  \n",
       "1346       film 3       Expecto Patronum  \n",
       "1504       film 3              Immobulus  \n",
       "1554       film 3       Expecto Patronum  \n",
       "1561       film 3               Bombarda  \n",
       "1601       film 3                   None  \n",
       "1634       film 3                  Lumos  \n",
       "1637       film 3                    Nox  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data = []\n",
    "def generate_training_data(row):\n",
    "    # Let's also add in blank_nlp\n",
    "    sentences = nltk.sent_tokenize(row.Sentence.lower())\n",
    "    for sentence in sentences:\n",
    "        spacy_full = spell_nlp(sentence)\n",
    "        list_entities = []\n",
    "        for token in spacy_full.ents:\n",
    "            list_entities.append([token.start_char, token.end_char, token.label_])\n",
    "        if len(list_entities) > 0:\n",
    "            entry = (sentence,{\"entities\": list_entities})\n",
    "            training_data.append(entry)\n",
    "    return row\n",
    "films_spells[films_spells.identified_spells.str.len() > 1].apply(generate_training_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('oculus reparo.', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('alohomora', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('alohomora?', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('wingardium leviosa.', {'entities': [[0, 18, 'SPELL']]}),\n",
       " ('wingardium leviosa.', {'entities': [[0, 18, 'SPELL']]}),\n",
       " ('wingardium leviosa!', {'entities': [[0, 18, 'SPELL']]}),\n",
       " (' petrificus totalus.', {'entities': [[1, 19, 'SPELL']]}),\n",
       " ('alohomora.', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('alohomora!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('oculus reparo.', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('peskipiksi pesternomi!', {'entities': [[0, 21, 'SPELL']]}),\n",
       " ('immobulus!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('vera verto.', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('vera verto.', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('vera verto!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('finite incantatem!', {'entities': [[0, 6, 'SPELL']]}),\n",
       " ('brackium emendo!', {'entities': [[0, 15, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('everte statum!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('rictusempra!', {'entities': [[0, 11, 'SPELL']]}),\n",
       " ('serpensortia!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('alarte ascendare!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('vipera evanesca.', {'entities': [[0, 15, 'SPELL']]}),\n",
       " ('wingardium leviosa.', {'entities': [[0, 18, 'SPELL']]}),\n",
       " ('cistem aperio!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('arania exumai!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('arania exumai!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('arania exumai!', {'entities': [[0, 13, 'SPELL']]}),\n",
       " ('lumos maxima...', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('lumos maxima...', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('lumos maxima...', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('lumos... maxima!', {'entities': [[0, 5, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('listen: riddikulus!', {'entities': [[8, 18, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('then speak the incantation, expecto patronum.',\n",
       "  {'entities': [[28, 44, 'SPELL']]}),\n",
       " ('expecto patronum.', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('nox.', {'entities': [[0, 3, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('immobulus!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('bombarda!', {'entities': [[0, 8, 'SPELL']]}),\n",
       " ('none of it made any difference.', {'entities': [[0, 4, 'SPELL']]}),\n",
       " ('lumos.', {'entities': [[0, 5, 'SPELL']]}),\n",
       " ('nox.', {'entities': [[0, 3, 'SPELL']]})]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For those in Williams' morning workshop you probably know what comes next. But now we need to manipulate our training data list into a format that works with spaCy 3.0\n",
    "\n",
    "Instead of ingesting json files, spaCy now requires that our data be stored in the proprietary `.spacy` format. To do that we need to use the `DocBin` class.\n",
    "\n",
    "I've included code from this Medium blog post https://towardsdatascience.com/using-spacy-3-0-to-build-a-custom-ner-model-c9256bea098. Let's rework the code into a function that takes a model, data, and file name, and then writes the data in the spacy format to file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import DocBin\n",
    "\n",
    "db = DocBin() \n",
    "\n",
    "for text, annot in training_data[19*2:]: \n",
    "    doc = spell_nlp.make_doc(text) \n",
    "    ents = []\n",
    "    for entity in annot[\"entities\"]:\n",
    "        start = entity[0]\n",
    "        end= entity[1]\n",
    "        label = entity[2]\n",
    "        span = doc.char_span(start, end, label=label, alignment_mode=\"contract\")\n",
    "        if span is None:\n",
    "            print(\"Skipping entity\")\n",
    "        else:\n",
    "            ents.append(span)\n",
    "    doc.ents = ents # label the text with the ents\n",
    "    db.add(doc)\n",
    "db.to_disk(f\"./valid_spells.spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('riddikulus!', {'entities': [[0, 10, 'SPELL']]}),\n",
       " ('then speak the incantation, expecto patronum.',\n",
       "  {'entities': [[28, 44, 'SPELL']]}),\n",
       " ('expecto patronum.', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('nox.', {'entities': [[0, 3, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expelliarmus!', {'entities': [[0, 12, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('immobulus!', {'entities': [[0, 9, 'SPELL']]}),\n",
       " ('expecto patronum!', {'entities': [[0, 16, 'SPELL']]}),\n",
       " ('bombarda!', {'entities': [[0, 8, 'SPELL']]}),\n",
       " ('none of it made any difference.', {'entities': [[0, 4, 'SPELL']]}),\n",
       " ('lumos.', {'entities': [[0, 5, 'SPELL']]}),\n",
       " ('nox.', {'entities': [[0, 3, 'SPELL']]})]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0:19*2], training_data[19*2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we run our custom training, we actually need evaulation data. Let's split our original training data into training and evaluation and then write them both to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can finally start training our model 🥳! Let's go to the spaCy docs https://spacy.io/usage/training#quickstart and we'll see that we need to download our base_config.\n",
    "\n",
    "Once we have that we can run the following code:\n",
    "```python\n",
    "!python -m spacy init fill-config base_config.cfg config.cfg\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will populate our config file with our relevant values. You'll notice in the Quickstart, there are multiple settings. We'll try out some of these later on today."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's finally run our model!\n",
    "\n",
    "```python\n",
    "!python -m spacy train config.cfg --output ./output/spells-model/ --paths.train ./train_spells.spacy --paths.dev ./valid_spells.spacy\n",
    "```\n",
    "This will likely take a while to run but I did run it earlier below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Created output directory: output/spells-model\u001b[0m\n",
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-07-02 11:02:39,791] [INFO] Set up nlp object from config\n",
      "[2021-07-02 11:02:39,801] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-07-02 11:02:39,806] [INFO] Created vocabulary\n",
      "[2021-07-02 11:02:44,275] [INFO] Added vectors: en_core_web_lg\n",
      "[2021-07-02 11:02:44,276] [INFO] Finished initializing nlp object\n",
      "[2021-07-02 11:02:44,547] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     83.83   24.00   19.35   31.58    0.24\n",
      "200     200          0.25    421.15   92.31   90.00   94.74    0.92\n",
      "400     400          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "600     600          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "800     800          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "1000    1000          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "1200    1200          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "1400    1400          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "1600    1600          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "1800    1800          0.00      0.00   92.31   90.00   94.74    0.92\n",
      "\u001b[38;5;2m✔ Saved pipeline to output directory\u001b[0m\n",
      "output/spells-model/model-last\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output/spells-model/ --paths.train ./train_spells.spacy --paths.dev ./valid_spells.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the spaCy docs to understand our output https://spacy.io/usage/training#metrics and https://spacy.io/usage/training#basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For evaluating our model, we can load in the best run of our model that is saved to the output file and see how it does with new unseen text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'ner']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_best = spacy.load('./output/spells-model/model-best')\n",
    "model_best.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best Ron Weasley SPELL\n",
      "best Wingardium Leviosa SPELL\n",
      "best Hermione Granger SPELL\n",
      "best saying SPELL\n",
      "best wrong SPELL\n",
      "best Wing SPELL\n",
      "best gar SPELL\n",
      "best dium Levi SPELL\n",
      "best gar SPELL\n",
      "best long SPELL\n",
      "best Ron Weasley SPELL\n",
      "blank Wingardium Leviosa SPELL\n"
     ]
    }
   ],
   "source": [
    "test_text = \"Ron Weasley: Wingardium Leviosa! Hermione Granger: You're saying it wrong. It's Wing-gar-dium Levi-o-sa, make the 'gar' nice and long. Ron Weasley: You do it, then, if you're so clever\"\n",
    "\n",
    "doc = model_best(test_text)\n",
    "for ent in doc.ents:\n",
    "    print('best', ent.text, ent.label_)\n",
    "\n",
    "# We can even comare this to our original blank model\n",
    "test_doc = spell_nlp(test_text)\n",
    "for ent in test_doc.ents:\n",
    "    print('blank', ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Such a short line is difficult to evaluate so let's try a longer line of text:\n",
    "\n",
    "```python\n",
    "test_text = \"\"\"53. Imperio - Makes target obey every command But only for really, really funny pranks. 52. Piertotum Locomotor - Animates statues On one hand, this is awesome. On the other, someone would use this to scare me.\n",
    "\n",
    "51. Aparecium - Make invisible ink appear\n",
    "\n",
    "Your notes will be so much cooler.\n",
    "\n",
    "50. Defodio - Carves through stone and steel\n",
    "\n",
    "Sometimes you need to get the eff out of there.\n",
    "\n",
    "49. Descendo - Moves objects downward\n",
    "\n",
    "You'll never have to get a chair to reach for stuff again.\n",
    "\n",
    "48. Specialis Revelio - Reveals hidden magical properties in an object\n",
    "\n",
    "I want to know what I'm eating and if it's magical.\n",
    "\n",
    "47. Meteolojinx Recanto - Ends effects of weather spells\n",
    "\n",
    "Otherwise, someone could make it sleet in your bedroom forever.\n",
    "\n",
    "46. Cave Inimicum/Protego Totalum - Strengthens an area's defenses\n",
    "\n",
    "Helpful, but why are people trying to break into your campsite?\n",
    "\n",
    "45. Impedimenta - Freezes someone advancing toward you\n",
    "\n",
    "\"Stop running at me! But also, why are you running at me?\"\n",
    "\n",
    "44. Obscuro - Blindfolds target\n",
    "\n",
    "Finally, we don't have to rely on \"No peeking.\"\n",
    "\n",
    "43. Reducto - Explodes object\n",
    "\n",
    "The \"raddest\" of all spells.\n",
    "\n",
    "42. Anapneo - Clears someone's airway\n",
    "\n",
    "This could save a life, but hopefully you won't need it.\n",
    "\n",
    "41. Locomotor Mortis - Leg-lock curse\n",
    "\n",
    "Good for footraces and Southwest Airlines flights.\n",
    "\n",
    "40. Geminio - Creates temporary, worthless duplicate of any object\n",
    "\n",
    "You could finally live your dream of lying on a bed of marshmallows, and you'd only need one to start.\n",
    "\n",
    "39. Aguamenti - Shoot water from wand\n",
    "\n",
    "No need to replace that fire extinguisher you never bought.\n",
    "\n",
    "38. Avada Kedavra - The Killing Curse\n",
    "\n",
    "One word: bugs.\n",
    "\n",
    "37. Repelo Muggletum - Repels Muggles\n",
    "\n",
    "Sounds elitist, but seriously, Muggles ruin everything. Take it from me, a Muggle.\n",
    "\n",
    "36. Stupefy - Stuns target\n",
    "\n",
    "Since this is every other word of the \"Deathly Hallows\" script, I think it's pretty useful.\"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So seems like in this instance our blank model performs better than our trained model. Why do we think that is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help us understand what's going on, let's try comparing our `SPELL` model to one trained on character names.\n",
    "\n",
    "Our list of rules for character names exist in `all_names` variable. First step is that we have to add our rules to a spaCy model. We could create a new blank model, but instead let's add it to our spell_nlp model, so that it can identify characters and spells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruler.add_patterns(all_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're also going to increase our training data by using data from all of the movie scripts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie</th>\n",
       "      <th>chapter</th>\n",
       "      <th>character</th>\n",
       "      <th>dialog</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Doorstep Delivery</td>\n",
       "      <td>Albus Dumbledore</td>\n",
       "      <td>I should have known that you would be here...P...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      movie            chapter  \\\n",
       "0  Harry Potter and the Philosopher's Stone  Doorstep Delivery   \n",
       "\n",
       "          character                                             dialog  \n",
       "0  Albus Dumbledore  I should have known that you would be here...P...  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in range(1,8):\n",
    "    df = pd.read_csv(f'./archive/hp{i}.csv')\n",
    "    dfs.append(df)\n",
    "hp_dfs = pd.concat(dfs)\n",
    "hp_dfs[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we need to build our training data and then convert it to the spaCy format. (Small hint make sure we use this format `hp_dfs[hp_dfs.dialog.isna()==False]`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CALL TRAINING FUNCTIONS HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4mℹ Using CPU\u001b[0m\n",
      "\u001b[1m\n",
      "=========================== Initializing pipeline ===========================\u001b[0m\n",
      "[2021-07-02 12:21:29,371] [INFO] Set up nlp object from config\n",
      "[2021-07-02 12:21:29,382] [INFO] Pipeline: ['tok2vec', 'ner']\n",
      "[2021-07-02 12:21:29,386] [INFO] Created vocabulary\n",
      "[2021-07-02 12:21:32,556] [INFO] Added vectors: en_core_web_lg\n",
      "[2021-07-02 12:21:32,556] [INFO] Finished initializing nlp object\n",
      "[2021-07-02 12:21:34,291] [INFO] Initialized pipeline components: ['tok2vec', 'ner']\n",
      "\u001b[38;5;2m✔ Initialized pipeline\u001b[0m\n",
      "\u001b[1m\n",
      "============================= Training pipeline =============================\u001b[0m\n",
      "\u001b[38;5;4mℹ Pipeline: ['tok2vec', 'ner']\u001b[0m\n",
      "\u001b[38;5;4mℹ Initial learn rate: 0.001\u001b[0m\n",
      "E    #       LOSS TOK2VEC  LOSS NER  ENTS_F  ENTS_P  ENTS_R  SCORE \n",
      "---  ------  ------------  --------  ------  ------  ------  ------\n",
      "  0       0          0.00     54.80    4.90   27.37    2.69    0.05\n",
      "  1     200         12.72    946.93   91.44   94.58   88.51    0.91\n",
      "  2     400         13.45     92.84   93.23   95.25   91.30    0.93\n",
      "  5     600         11.02     38.52   93.86   95.21   92.55    0.94\n",
      "  7     800          8.96     28.72   93.37   95.76   91.10    0.93\n",
      " 10    1000         17.49     24.33   93.33   96.26   90.58    0.93\n",
      " 14    1200         13.66     18.10   93.36   93.56   93.17    0.93\n",
      " 19    1400         15.73     16.44   93.31   95.75   90.99    0.93\n",
      " 24    1600         12.84     17.32   92.11   93.59   90.68    0.92\n",
      " 31    1800         76.71     89.64   93.14   94.27   92.03    0.93\n",
      " 40    2000         45.42     48.16   93.42   94.97   91.93    0.93\n",
      " 50    2200         16.61     13.42   94.06   95.61   92.55    0.94\n",
      " 62    2400          0.00      0.00   94.06   95.61   92.55    0.94\n",
      " 75    2600          0.00      0.00   94.06   95.61   92.55    0.94\n",
      " 87    2800          0.00      0.00   94.06   95.61   92.55    0.94\n",
      "100    3000          0.00      0.00   94.06   95.61   92.55    0.94\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train config.cfg --output ./output/person-model/ --paths.train ./train_person.spacy --paths.dev ./valid_person.spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're getting pretty decent results. We could try and find more data (making scraping fanfiction?) but overall this isn't bad considering we still know we have issues with some character names (like Ginny and Ron).\n",
    "\n",
    "Part of the reason we aren't getting better results is something that Ines Montani describes in this Stack Overflow answer https://stackoverflow.com/questions/50580262/how-to-use-spacy-to-create-a-new-entity-and-learn-only-from-keyword-list/50603247#50603247\n",
    "\n",
    "\"The advantage of training the named entity recognizer to detect SPECIES in your text is that the model won't only be able to recognise your examples, but also generalise and recognise other species in context. If you only want to find a fixed set of terms and not more, a simpler, rule-based approach might work better for you. You can find examples and details of this here.\n",
    "\n",
    "If you do want the model to generalise and recognise your entity type in context, you also have to show it examples of the entities in context. That's currently the problem with your training examples: you're only showing the model single words, not sentences containing the words. To get good results, the data you're training the model with needs to be as close as possible to the data you later want to analyse.\n",
    "\n",
    "While there are other approaches for training models without or with fewer labelled examples, the most straightforward strategy for collecting training data to train your spaCy model is to... label training data. However, there are some tricks you can use to make this less painful:\n",
    "\n",
    "Start with a list of species and use the Matcher or PhraseMatcher to find them in your documents. For each match, you'll get a Span object, so you can extract the start and end position of the span in the text. This easily lets you create a bunch of examples automatically. You can find some more details on this here.\n",
    "\n",
    "Use word vectors to find more similar terms to the entities you're looking for, so you get more examples you can search for in your text using the above approach. I'm not sure how spaCy's vector models will do for your species, since the terms are quite specific. So if you have a large corpus of raw text containing species, you might have to train your own vectors.\n",
    "\n",
    "Use a labelling or data annotation tool. There are open-source solutions like Brat, or, once you're getting more serious about annotation and training, you might also want to check out our annotation tool Prodigy, which is a modern commercial solution that integrates seamlessly with spaCy (Disclaimer: I'm one of the spaCy maintainers).\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These final two options of word vectors or using a data annotation tool are things we have yet to discuss.\n",
    "\n",
    "spaCy actually offers a popular data annotation tool called Prodigy https://prodi.gy/ (though it does require buying a license). Another popular and free tool is INCEpTION https://inception-project.github.io/. You can find a good overview of the many tools available https://bohemian.ai/blog/text-annotation-tools-which-one-pick-2020/ here. \n",
    "\n",
    "Let's try out the option of word vectors though. Say we didn't have character names how could we generate some example entities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first option would be just adding all our film script data to a spaCy pre-trained model and then extracting the named entities as a our initial training data.\n",
    "\n",
    "The other option is using gensim to create Custom Word Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#training-your-own-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sentences = []\n",
    "import string\n",
    "import nltk\n",
    "\n",
    "def build_corpus(row):\n",
    "    sentences = nltk.sent_tokenize(row.Sentence)\n",
    "    for sent in sentences:\n",
    "        cleaned_sentence = sent.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "        list_sentences.append(cleaned_sentence.split())\n",
    "\n",
    "films_df.apply(build_corpus, axis=1)\n",
    "# list_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=1,\n",
    "    window=2,\n",
    "    vector_size=10,\n",
    "    sample=6e-5,\n",
    "    alpha=0.03,\n",
    "    min_alpha=0.0007,\n",
    "    negative=20)\n",
    "w2v_model.build_vocab(list_sentences, progress_per=10000)\n",
    "w2v_model.train(list_sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = w2v_model.wv\n",
    "word_vectors.most_similar('professor')\n",
    ".save_word2vec_format(\"./data/word2vec.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init vectors en vectors.txt output/vector-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_model = spacy.load('./output/vector-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sentence in films_df.Sentence.tolist()[0:10]:\n",
    "    doc = vector_model(sentence)\n",
    "    for ent in doc.ents:\n",
    "        print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://explosion.ai/blog/pseudo-rehearsal-catastrophic-forgetting\n",
    "\n",
    "https://en.wikipedia.org/wiki/Catastrophic_interference"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c11445b2f880dceb70b92bfd87cba8fb4787433921a65f450e3d775bea6b0bcf"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('ner_hum_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}