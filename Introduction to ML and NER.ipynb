{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Machine Learning and NER\n",
    "\n",
    "Today's Goals/Agenda:\n",
    "- Review homework exercises and deeper dive into spaCy\n",
    "- Discussion of how we evaluate NER models and libraries\n",
    "- Building and training custom NER models\n",
    "\n",
    "Let's start with our homework from Monday ü•≥!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download Spacy in Binder\n",
    "# !pip install -U pip setuptools wheel\n",
    "# !pip install -U spacy\n",
    "# !python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download Spacy if running locally\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install spacy\n",
    "# !{sys.executable} -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's all our code from Monday compiled into one cell üò≥üëáüèΩ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our data\n",
    "chars_df = pd.read_csv('./archive/Characters.csv', delimiter=';')\n",
    "chars_df['split_names'] = chars_df.Name.str.split(' ')\n",
    "film1_df = pd.read_csv('./archive/Harry Potter 1.csv', delimiter=';')\n",
    "# Load in our spaCy model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def find_entities(row):\n",
    "    # Find character names from chars_df\n",
    "    character_names = chars_df.split_names.tolist()\n",
    "    identified_names = []\n",
    "    for names in character_names:\n",
    "        if any(name in row.Sentence for name in names):\n",
    "            identified_names.append(' '.join(names))\n",
    "    row['identified_names'] = identified_names\n",
    "    return row\n",
    "\n",
    "film1_entities = film1_df.apply(find_entities, axis=1)\n",
    "film1_entities = film1_entities[film1_entities.identified_names.astype(bool)]\n",
    "film1_exploded = film1_entities.explode('identified_names')\n",
    "\n",
    "film1_exploded['sentence_lower'] = film1_exploded.Sentence.str.lower()\n",
    "chars_df['name_lower'] = chars_df.Name.str.lower()\n",
    "\n",
    "# Build our first rules-based NER model with spaCy\n",
    "chars_df['first_name'] = chars_df.split_names.str[0].str.lower()\n",
    "chars_df['last_name'] = chars_df.split_names.str[-1].str.lower()\n",
    "\n",
    "first_names = chars_df.first_name.unique().tolist()\n",
    "last_names = chars_df.last_name.unique().tolist()\n",
    "\n",
    "names = list(set(first_names) | set(last_names))\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "list_names = [{\"label\": \"PERSON\", \"pattern\": f\"{name}\"} for name in names]\n",
    "\n",
    "ruler.add_patterns(list_names)\n",
    "\n",
    "def find_spacy_entities(row):\n",
    "    # code goes here\n",
    "    spacy_sentence = nlp(row.Sentence.lower())\n",
    "    \n",
    "    list_tokens = []\n",
    "    list_entities = []\n",
    "    for token in spacy_sentence.ents:\n",
    "        list_tokens.append(token.text)\n",
    "        list_entities.append(token.label_)\n",
    "    row['spacy_tokens'] = list_tokens\n",
    "    row['spacy_entities'] = list_entities\n",
    "    return row\n",
    "\n",
    "film1_df = film1_df.apply(find_spacy_entities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's review the first option for the homework (don't worry we'll get to the second dataset and option later).\n",
    "\n",
    "For the Harry Potter dataset, here are the following steps:\n",
    "- Load in the other scripts and join them with our first film\n",
    "- Rerun our code for identifying characters (NER algorithm and spaCy model)\n",
    "If you get through that quickly:\n",
    "- Try improving our code to produce better character results (maybe get spaCy working with bigrams?)\n",
    "- Try expanding our custom named entities patterns to also include other entities, such as locations like Hogwarts and Diagon Alley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load film datasets\n",
    "film1_df = pd.read_csv('./archive/Harry Potter 1.csv', delimiter=';')\n",
    "film2_df = pd.read_csv('./archive/Harry Potter 2.csv', delimiter=';')\n",
    "film3_df = pd.read_csv('./archive/Harry Potter 3.csv', delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I should've known that you would be here, Prof...</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Good evening, Professor Dumbledore.</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Are the rumors true, Albus?</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I'm afraid so, professor.</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>The good and the bad.</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Character                                           Sentence movie_number\n",
       "0  Dumbledore  I should've known that you would be here, Prof...       film 1\n",
       "1  McGonagall                Good evening, Professor Dumbledore.       film 1\n",
       "2  McGonagall                        Are the rumors true, Albus?       film 1\n",
       "3  Dumbledore                          I'm afraid so, professor.       film 1\n",
       "4  Dumbledore                              The good and the bad.       film 1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine film dataframes\n",
    "film3_df.columns = map(str.capitalize, film3_df.columns)\n",
    "film1_df['movie_number'] = 'film 1'\n",
    "film2_df['movie_number'] = 'film 2'\n",
    "film3_df['movie_number'] = 'film 3'\n",
    "films_df = pd.concat([film1_df, film2_df, film3_df])\n",
    "films_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify Character Names for full name datasets using our original functions\n",
    "\n",
    "films_entities = films_df.apply(find_entities, axis=1)\n",
    "\n",
    "films_spacy = films_df.apply(find_spacy_entities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>spacy_tokens</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>identified_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>mcgonagall</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Minerva McGonagall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>mcgonagall</td>\n",
       "      <td>film 1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>mcgonagall</td>\n",
       "      <td>film 1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>mcgonagall</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Rubeus Hagrid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>mcgonagall</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Rubeus Hagrid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Character spacy_tokens movie_number    identified_names\n",
       "0  Dumbledore   mcgonagall       film 1  Minerva McGonagall\n",
       "1  Dumbledore   mcgonagall       film 1                    \n",
       "2  Dumbledore   mcgonagall       film 1                    \n",
       "3  Dumbledore   mcgonagall       film 1       Rubeus Hagrid\n",
       "4  Dumbledore   mcgonagall       film 1       Rubeus Hagrid"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge our NER algorithm identified names with those identified by spaCy. We could now remake our sankey graph from Monday using https://rawgraphs.io/.\n",
    "\n",
    "identified_names = films_entities.explode('identified_names')\n",
    "identified_names = identified_names[['Character', 'identified_names', 'movie_number']]\n",
    "spacy_names = films_spacy.set_index(['Character', 'Sentence', 'movie_number']).apply(pd.Series.explode).reset_index()\n",
    "spacy_names = spacy_names[spacy_names.spacy_entities == 'PERSON'][['Character', 'spacy_tokens', 'movie_number']]\n",
    "merged_names = pd.merge(spacy_names, identified_names, on=['Character', 'movie_number'], how='outer')\n",
    "merged_names = merged_names.fillna('')\n",
    "merged_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just to review what we've done above is extend spaCy's rules-based NER. From William Mattingly's textbook:\n",
    "> Rules-based NER is the method by which an NLP practitioner either creates or utalizes an NLP system that has a predefined set of instructions, or rules, to perform certain NLP tasks. For NER, this often times means using what is known as a gazetteer. A gazetteer is a list, or dictionary, of entities that align with a specific label. In the case of people, this would be a list of first and last names. If you are developing an NER for a specific region, as we will in a later notebook, this may be a list of all locations in that region.\n",
    "\n",
    "(Just FYI the code in William's textbook will not work with the lastest 3.0 version of Spacy, more info here https://spacy.io/usage/v3#migrating)\n",
    "\n",
    "Rules-based NER works well when we have a set number of patterns and entities we want to identify within a text. It works particularly well if you're using a gazetteer or a pre-defined list of entities (and not so well if you think your text data will have a lot of variation - whether errors or otherwise - or a lot of overlapping meaning between words).\n",
    "\n",
    "Our code from above:\n",
    "```python\n",
    "ruler = nlp.add_pipe(\"entity_ruler\")\n",
    "list_names = [{\"label\": \"PERSON\", \"pattern\": f\"{name}\"} for name in names]\n",
    "\n",
    "ruler.add_patterns(list_names)\n",
    "```\n",
    "is using spaCy's **EntityRuler** to create a new pipeline for our NER model. According to the spaCy documentation https://spacy.io/usage/rule-based-matching#entityruler:\n",
    "\n",
    "> The EntityRuler is a component that lets you add named entities based on pattern dictionaries, which makes it easy to combine rule-based and statistical named entity recognition for even more powerful pipelines.\n",
    "\n",
    "The statistical part of our pipeline is the original spacy model (which in our current code is the small english web model).\n",
    "\n",
    "Accoring to that same documentation:\n",
    "\n",
    "> The entity ruler is designed to integrate with spaCy‚Äôs existing pipeline components and enhance the named entity recognizer. If it‚Äôs added before the \"ner\" component, the entity recognizer will respect the existing entity spans and adjust its predictions around it. This can significantly improve accuracy in some cases. If it‚Äôs added after the \"ner\" component, the entity ruler will only add spans to the doc.ents if they don‚Äôt overlap with existing entities predicted by the model. To overwrite overlapping entities, you can set overwrite_ents=True on initialization.\n",
    "\n",
    "With this in mind, let's try improving on our initial output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the first things we can do is try and use both full names and individual names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "chars_df['full_names'] = np.where(\n",
    "    chars_df.split_names.str.len() == 2, \n",
    "    chars_df.split_names.str[0].str.lower() + ' ' + chars_df.split_names.str[1].str.lower(), \n",
    "    np.where(\n",
    "        chars_df.split_names.str.len() > 2,\n",
    "        chars_df.split_names.str[0].str.lower() + ' ' + chars_df.split_names.str[-1].str.lower(),\n",
    "        chars_df.split_names.str[0].str.lower())) \n",
    "\n",
    "full_names = chars_df.full_names.unique().tolist()\n",
    "first_names = chars_df.first_name.unique().tolist()\n",
    "last_names = chars_df.last_name.unique().tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now that we have our full names we can update our model. Let's follow this example in the spaCy documentation https://spacy.io/usage/rule-based-matching#entityruler-ent-ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example rule {'label': 'PERSON', 'pattern': [{'LOWER': 'binns'}], 'id': 'binns'}\n"
     ]
    }
   ],
   "source": [
    "# Get unique names and create our rules\n",
    "names = list(set(first_names) | set(last_names))\n",
    "unique_names = list(set(names) | set(full_names))\n",
    "list_names = [{\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": f\"{name}\"}], \"id\": f\"{name}\"} for name in unique_names if len(name.split(' ')) == 1]\n",
    "\n",
    "list_full_names = [{\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": f\"{name.split(' ')[0]}\"}, {\"LOWER\": f\"{name.split(' ')[1]}\"}], \"id\": f\"{'-'.join(name.split(' '))}\"} for name in full_names if len(name.split(' ')) > 1]\n",
    "\n",
    "all_names = list_names + list_full_names\n",
    "print('example rule', all_names[0])\n",
    "\n",
    "# Load our models and pass our rules\n",
    "full_nlp = spacy.load(\"en_core_web_sm\")\n",
    "ruler = full_nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(all_names)\n",
    "\n",
    "blank_nlp = spacy.blank(\"en\")\n",
    "ruler = blank_nlp.add_pipe(\"entity_ruler\")\n",
    "ruler.add_patterns(all_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've created two separate models above. One contains our initial spaCy model (the English web small version) and then a blank spaCy model. We've added the same type of EntityRuler and rules to each model, so now we can compare them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_spacy_models(row):\n",
    "    # Read in text data\n",
    "    spacy_full = full_nlp(row.Sentence)\n",
    "    spacy_blank = blank_nlp(row.Sentence)\n",
    "    list_tokens = []\n",
    "    list_entities = []\n",
    "    for token in spacy_full.ents:\n",
    "        list_tokens.append(token.text)\n",
    "        list_entities.append(token.label_)\n",
    "    row['spacy_full_tokens'] = ', '.join(list_tokens)\n",
    "    row['spacy_full_entities'] = ', '.join(list_entities)\n",
    "\n",
    "    list_tokens = []\n",
    "    list_entities = []\n",
    "    for token in spacy_blank.ents:\n",
    "        list_tokens.append(token.text)\n",
    "        list_entities.append(token.label_)\n",
    "    row['spacy_blank_tokens'] = ', '.join(list_tokens)\n",
    "    row['spacy_blank_entities'] = ', '.join(list_entities)\n",
    "    return row\n",
    "\n",
    "spacy_films = films_df.apply(compare_spacy_models, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see which entities character names were identified as different between our two spacy models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>spacy_full_tokens</th>\n",
       "      <th>spacy_full_entities</th>\n",
       "      <th>spacy_blank_tokens</th>\n",
       "      <th>spacy_blank_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Good evening, Professor Dumbledore.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>evening, Dumbledore</td>\n",
       "      <td>TIME, PERSON</td>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Harry</td>\n",
       "      <td>Yes, Aunt Petunia.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Aunt Petunia</td>\n",
       "      <td>LOC</td>\n",
       "      <td>Petunia</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Harry</td>\n",
       "      <td>Yes, Uncle Vernon.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Uncle Vernon</td>\n",
       "      <td>PERSON</td>\n",
       "      <td>Vernon</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>Dudley</td>\n",
       "      <td>Dad, look! Harry's got a letter!</td>\n",
       "      <td>film 1</td>\n",
       "      <td>Dad, Harry</td>\n",
       "      <td>PERSON, PERSON</td>\n",
       "      <td>Harry</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Vernon</td>\n",
       "      <td>Not one single bloody letter. Not one!</td>\n",
       "      <td>film 1</td>\n",
       "      <td>one, bloody</td>\n",
       "      <td>CARDINAL, PERSON</td>\n",
       "      <td>bloody</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Listen Harry, they've captured Sirius.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Listen Harry, Sirius</td>\n",
       "      <td>PERSON, PERSON</td>\n",
       "      <td>Harry, Sirius</td>\n",
       "      <td>PERSON, PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1374</th>\n",
       "      <td>DUMBLEDORE</td>\n",
       "      <td>Sirius Black is in the topmost cell of the Dar...</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Sirius Black, the Dark Tower</td>\n",
       "      <td>PERSON, FAC</td>\n",
       "      <td>Sirius Black</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>This is a Time-Turner, Harry.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>a Time-Turner, Harry</td>\n",
       "      <td>ORG, PERSON</td>\n",
       "      <td>Harry</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1400</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>McGonagall gave it to me first term.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>McGonagall, first</td>\n",
       "      <td>PERSON, ORDINAL</td>\n",
       "      <td>McGonagall</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1421</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>Fudge has to see Buckbeak before we steal him.</td>\n",
       "      <td>film 3</td>\n",
       "      <td>Fudge, Buckbeak</td>\n",
       "      <td>PERSON, ORG</td>\n",
       "      <td>Fudge</td>\n",
       "      <td>PERSON</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>179 rows √ó 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Character                                           Sentence  \\\n",
       "1     McGonagall                Good evening, Professor Dumbledore.   \n",
       "36         Harry                                 Yes, Aunt Petunia.   \n",
       "39         Harry                                 Yes, Uncle Vernon.   \n",
       "107       Dudley                   Dad, look! Harry's got a letter!   \n",
       "120       Vernon             Not one single bloody letter. Not one!   \n",
       "...          ...                                                ...   \n",
       "1352    HERMIONE             Listen Harry, they've captured Sirius.   \n",
       "1374  DUMBLEDORE  Sirius Black is in the topmost cell of the Dar...   \n",
       "1399    HERMIONE                      This is a Time-Turner, Harry.   \n",
       "1400    HERMIONE               McGonagall gave it to me first term.   \n",
       "1421    HERMIONE     Fudge has to see Buckbeak before we steal him.   \n",
       "\n",
       "     movie_number             spacy_full_tokens spacy_full_entities  \\\n",
       "1          film 1           evening, Dumbledore        TIME, PERSON   \n",
       "36         film 1                  Aunt Petunia                 LOC   \n",
       "39         film 1                  Uncle Vernon              PERSON   \n",
       "107        film 1                    Dad, Harry      PERSON, PERSON   \n",
       "120        film 1                   one, bloody    CARDINAL, PERSON   \n",
       "...           ...                           ...                 ...   \n",
       "1352       film 3          Listen Harry, Sirius      PERSON, PERSON   \n",
       "1374       film 3  Sirius Black, the Dark Tower         PERSON, FAC   \n",
       "1399       film 3          a Time-Turner, Harry         ORG, PERSON   \n",
       "1400       film 3             McGonagall, first     PERSON, ORDINAL   \n",
       "1421       film 3               Fudge, Buckbeak         PERSON, ORG   \n",
       "\n",
       "     spacy_blank_tokens spacy_blank_entities  \n",
       "1            Dumbledore               PERSON  \n",
       "36              Petunia               PERSON  \n",
       "39               Vernon               PERSON  \n",
       "107               Harry               PERSON  \n",
       "120              bloody               PERSON  \n",
       "...                 ...                  ...  \n",
       "1352      Harry, Sirius       PERSON, PERSON  \n",
       "1374       Sirius Black               PERSON  \n",
       "1399              Harry               PERSON  \n",
       "1400         McGonagall               PERSON  \n",
       "1421              Fudge               PERSON  \n",
       "\n",
       "[179 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_subset = spacy_films[(spacy_films.spacy_full_tokens.str.len() > 1) & (spacy_films.spacy_blank_tokens.str.len() > 1)]\n",
    "spacy_subset[spacy_subset.spacy_full_tokens != spacy_subset.spacy_blank_tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we're getting some differing results, if we actually added a condition to our function (`if token.label_ == 'PERSON'`) we would get exact results. This on one level makes sense, since we passed in our identical rules. But actually this identical results also has to do with our entities being fairly unique (not many multiple meanings for names like Hermione for example).\n",
    "\n",
    "One cautionary note is that this might not be true for your data. So let's test an example where we might not get identical results.\n",
    "\n",
    "For example, if we added this label to our code above for our rules:\n",
    "```python\n",
    "scotland = {\"label\": \"PERSON\", \"pattern\": [{\"LOWER\": \"scotland\"}], \"id\":\"scotland\"}\n",
    "list_names.append(scotland)\n",
    "```\n",
    "And then ran our models again with the term `Scotland`:\n",
    "```python\n",
    "scotland = full_nlp(\"Scotland\")\n",
    "scotland2 = blank_nlp(\"Scotland\")\n",
    "[print(token.text, token.label_) for token in scotland.ents]\n",
    "[print(token.text, token.label_) for token in scotland2.ents]\n",
    "```\n",
    "We would actually get two separate entity types (`GPE` or `PERSON` for the full and blank models respectively). \n",
    "\n",
    "This result is because currently when we add our rules to the existing model, we are adding them to an existing pipeline, which already has `Scotland` as an entity. We can either overwrite these entities (passing in `full_nlp.add_pipe(\"entity_ruler\", config={\"overwrite\":True})`) or tell spaCy to put our rules at the beginning of the pipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "#### Evaluating Spacy Models\n",
    "\n",
    "So far we've been eyeballing our results but we can actually use spaCy to score each of our models. Let's try reworking our code in our `compare_spacy_models` function. We'll be using spaCy's Scorer https://spacy.io/api/scorer and Example https://spacy.io/api/example classes to evaluate our models.\n",
    "\n",
    "First we need to extract our text data and entities in the correct format (like in this StackOverflow post https://stackoverflow.com/questions/66637485/spacy-3-0-1-accuracy-prediction). We can also refer to William's textbook http://ner.pythonhumanities.com/04_02_create_ner_training_set.html though we are using this syntax to evaluate, not create training data at the moment.\n",
    "\n",
    "The overall syntax we need is a list of tuples containing the original sentence, and then the identified entities within it, along with their start, end, and label.\n",
    "\n",
    "```python\n",
    "test_data = [\n",
    "    (\"Trump says he's answered Mueller's Russia inquiry questions \\u2013 \n",
    "    live\",{\"entities\":[[0,5,\"PERSON\"],[25,32,\"PERSON\"],[35,41,\"GPE\"]]}),\n",
    "    (\"Alexander Zverev reaches ATP Finals semis then reminds Lendl who is \n",
    "    boss\",{\"entities\":[[0,16,\"PERSON\"],[55,60,\"PERSON\"]]}),\n",
    "    (\"Britain's worst landlord to take nine years to pay off string of fines\", \n",
    "    {\"entities\":[[0,7,\"GPE\"]]}),\n",
    "    (\"Tom Watson: people's vote more likely given weakness of May's position\", \n",
    "    {\"entities\":[[0,10,\"PERSON\"],[56,59,\"PERSON\"]]}),\n",
    "]\n",
    "```\n",
    "So how might we extract this information using our original function as an example?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I should've known that you would be here, Prof...</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Good evening, Professor Dumbledore.</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Are the rumors true, Albus?</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I'm afraid so, professor.</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>The good and the bad.</td>\n",
       "      <td>film 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>HERMIONE</td>\n",
       "      <td>How fast is it, Harry?</td>\n",
       "      <td>film 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Lumos.</td>\n",
       "      <td>film 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>I solemnly swear that I am up to no good.</td>\n",
       "      <td>film 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Mischief managed.</td>\n",
       "      <td>film 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>HARRY</td>\n",
       "      <td>Nox.</td>\n",
       "      <td>film 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4925 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Character                                           Sentence  \\\n",
       "0     Dumbledore  I should've known that you would be here, Prof...   \n",
       "1     McGonagall                Good evening, Professor Dumbledore.   \n",
       "2     McGonagall                        Are the rumors true, Albus?   \n",
       "3     Dumbledore                          I'm afraid so, professor.   \n",
       "4     Dumbledore                              The good and the bad.   \n",
       "...          ...                                                ...   \n",
       "1633    HERMIONE                             How fast is it, Harry?   \n",
       "1634       HARRY                                             Lumos.   \n",
       "1635       HARRY          I solemnly swear that I am up to no good.   \n",
       "1636       HARRY                                  Mischief managed.   \n",
       "1637       HARRY                                               Nox.   \n",
       "\n",
       "     movie_number  \n",
       "0          film 1  \n",
       "1          film 1  \n",
       "2          film 1  \n",
       "3          film 1  \n",
       "4          film 1  \n",
       "...           ...  \n",
       "1633       film 3  \n",
       "1634       film 3  \n",
       "1635       film 3  \n",
       "1636       film 3  \n",
       "1637       film 3  \n",
       "\n",
       "[4925 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "evaluation_data = []\n",
    "def evaluate_spacy_models(row):\n",
    "    # Let's also add in blank_nlp\n",
    "    sentences = nltk.sent_tokenize(row.Sentence.lower())\n",
    "    for sentence in sentences:\n",
    "        spacy_full = full_nlp(sentence)\n",
    "        list_entities = []\n",
    "        for token in spacy_full.ents:\n",
    "            list_entities.append([token.start_char, token.end_char, token.label_])\n",
    "        if len(list_entities) > 0:\n",
    "            entry = (sentence,{\"entities\": list_entities})\n",
    "            evaluation_data.append(entry)\n",
    "    return row\n",
    "films_df.apply(evaluate_spacy_models, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice here that we are taking all our identified entities as evaluation data. We could however do something like a train-test-split here, but since we want to evaluate how well our model has learned our entities this approach of taking all entities works well enough.\n",
    "\n",
    "Let's try evaluating our model using the following code that I adapted from this Github issue https://github.com/explosion/spaCy/discussions/8178#discussioncomment-781241. It's worth clicking on the issue and taking a look at spaCy's discussion section on Github."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_acc': 1.0, 'token_p': 1.0, 'token_r': 1.0, 'token_f': 1.0, 'sents_p': 1.0, 'sents_r': 1.0, 'sents_f': 1.0, 'tag_acc': None, 'pos_acc': None, 'morph_acc': None, 'morph_per_feat': None, 'dep_uas': None, 'dep_las': None, 'dep_las_per_type': None, 'ents_p': 1.0, 'ents_r': 1.0, 'ents_f': 1.0, 'ents_per_type': {'PERSON': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'CARDINAL': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'TIME': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'ORDINAL': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NORP': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'QUANTITY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}, 'cats_score': 0.0, 'cats_score_desc': 'macro F', 'cats_micro_p': 0.0, 'cats_micro_r': 0.0, 'cats_micro_f': 0.0, 'cats_macro_p': 0.0, 'cats_macro_r': 0.0, 'cats_macro_f': 0.0, 'cats_macro_auc': 0.0, 'cats_f_per_type': {}, 'cats_auc_per_type': {}}\n"
     ]
    }
   ],
   "source": [
    "from spacy.scorer import Scorer\n",
    "from spacy.training import Example\n",
    "\n",
    "# evaluate function\n",
    "def evaluate(ner_model, testing_data):\n",
    "    scorer = Scorer()\n",
    "    examples = []\n",
    "    for input_, annot in testing_data:\n",
    "        doc_gold_text = ner_model.make_doc(input_)\n",
    "        example = Example.from_dict(doc_gold_text, annot)\n",
    "        example.predicted = ner_model(input_)\n",
    "        examples.append(example)\n",
    "        \n",
    "    print(scorer.score(examples))\n",
    "\n",
    "# print the results\n",
    "evaluate(full_nlp, evaluation_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the full model first we see that we get back a dictionnary with lots of values. We can checkout the documentation for the Scorer https://spacy.io/api/scorer#score (though it's not particularly helpful in my opinion).Let's take a look at `'ents_per_type'`.\n",
    "\n",
    "`'ents_per_type': {'PERSON': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'CARDINAL': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'DATE': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'TIME': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'ORDINAL': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'NORP': {'p': 1.0, 'r': 1.0, 'f': 1.0}, 'QUANTITY': {'p': 1.0, 'r': 1.0, 'f': 1.0}}`\n",
    "\n",
    "This part of the scorer is actually giving us precision, recall, and f1 scores for each of the NER labels in this model.\n",
    "\n",
    "We could try running with the blank_nlp model, and what do you expect we would get instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can see that at least that the model seems to be accurately assessing our NER labels, though it's difficult to tell without doing a train-test-split to evaluate it actually (don't worry we'll try that later on today).\n",
    "\n",
    "An easier way to assess our model is to try and feed it new unseen text before. Below I've copied a section from the Harry Potter wiki page. Let's look at the results!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blank Harry Potter PERSON\n",
      "blank Harry PERSON\n",
      "blank Weasley PERSON\n",
      "blank Tom PERSON\n",
      "blank Riddle PERSON\n",
      "blank Tom Riddle PERSON\n",
      "blank Gilderoy Lockhart PERSON\n",
      "blank Harry PERSON\n",
      "blank Harry PERSON\n",
      "blank Hermione PERSON\n",
      "blank Harry PERSON\n",
      "blank Harry PERSON\n",
      "blank Lucius Malfoy PERSON\n",
      "blank Draco PERSON\n",
      "full Harry Potter PERSON\n",
      "full the Chamber of Secrets ORG\n",
      "full Harry PERSON\n",
      "full second year DATE\n",
      "full Hogwarts ORG\n",
      "full 50-year-old DATE\n",
      "full Ron PERSON\n",
      "full Ginny Weasley PERSON\n",
      "full her first year DATE\n",
      "full Hogwarts ORG\n",
      "full Tom Marvolo Riddle PERSON\n",
      "full World War II EVENT\n",
      "full Voldemort ORG\n",
      "full Tom Riddle PERSON\n",
      "full Ginny PERSON\n",
      "full Voldemort ORG\n",
      "full Ginny ORG\n",
      "full Voldemort ORG\n",
      "full Hogwarts PRODUCT\n",
      "full Defence Against the Dark Arts ORG\n",
      "full Gilderoy Lockhart PERSON\n",
      "full Harry PERSON\n",
      "full the Wizarding World LOC\n",
      "full Voldemort PERSON\n",
      "full Muggles PERSON\n",
      "full Harry PERSON\n",
      "full the Dark Arts ORG\n",
      "full Hermione PERSON\n",
      "full Harry PERSON\n",
      "full Ron PERSON\n",
      "full the Chamber of Secrets ORG\n",
      "full Harry PERSON\n",
      "full Ginny PERSON\n",
      "full Voldemort ORG\n",
      "full Lucius Malfoy PERSON\n",
      "full Draco ORG\n",
      "full Ron PERSON\n",
      "full Ginny PERSON\n",
      "full Ginny PERSON\n"
     ]
    }
   ],
   "source": [
    "# https://en.wikipedia.org/wiki/Harry_Potter\n",
    "test_text = \"The series continues with Harry Potter and the Chamber of Secrets, describing Harry's second year at Hogwarts. He and his friends investigate a 50-year-old mystery that appears uncannily related to recent sinister events at the school. Ron's younger sister, Ginny Weasley, enrols in her first year at Hogwarts, and finds an old notebook in her belongings which turns out to be the diary of a previous student, Tom Marvolo Riddle, written during World War II. He is later revealed to be Voldemort's younger self, who is bent on ridding the school of 'mudbloods', a derogatory term describing wizards and witches of non-magical parentage. The memory of Tom Riddle resides inside of the diary and when Ginny begins to confide in the diary, Voldemort is able to possess her. Through the diary, Ginny acts on Voldemort's orders and unconsciously opens the 'Chamber of Secrets', unleashing an ancient monster, later revealed to be a basilisk, which begins attacking students at Hogwarts. It kills those who make direct eye contact with it and petrifies those who look at it indirectly. The book also introduces a new Defence Against the Dark Arts teacher, Gilderoy Lockhart, a highly cheerful, self-conceited wizard with a pretentious facade, later turning out to be a fraud. Harry discovers that prejudice exists in the Wizarding World through delving into the school's history, and learns that Voldemort's reign of terror was often directed at wizards and witches who were descended from Muggles. Harry also learns that his ability to speak the snake language Parseltongue is rare and often associated with the Dark Arts. When Hermione is attacked and petrified, Harry and Ron finally piece together the puzzles and unlock the Chamber of Secrets, with Harry destroying the diary for good and saving Ginny, and, as they learn later, also destroying a part of Voldemort's soul. The end of the book reveals Lucius Malfoy, Draco's father and rival of Ron and Ginny's father, to be the culprit who slipped the book into Ginny's belongings.\"\n",
    "\n",
    "doc = blank_nlp(test_text)\n",
    "for token in doc.ents:\n",
    "    print('blank', token.text, token.label_)\n",
    "\n",
    "doc = full_nlp(test_text)\n",
    "for token in doc.ents:\n",
    "    print('full', token.text, token.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running, you'll notice we are getting very different results üëÄ.\n",
    "\n",
    "Particularly I was surprised to see that the blank_nlp model did not pickup Ron or Ginny as Persons compared to the full_nlp model. Looking in our chars_df for those two gives us some clues as to why.\n",
    "\n",
    "```python\n",
    "chars_df[chars_df.Name.str.contains('Ron|Ginny')]\n",
    "```\n",
    "\n",
    "But even with our data erros, our results also give us a sense of why you might want to use a spaCy model and add your labels, rather than train a blank one. And that's because spaCy models are able to generalize patterns (which to be fair does gives us some incorrect results) and capture both our rules (and prioritze them depending on how we build our pipeline), as well as entities we don't explicitly list out.\n",
    "\n",
    "How does spaCy do this? Let's take a look inside the model to figure it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To save spaCy models to disk, use the following syntax. Be careful though to not name it the same as a downloaded spaCy model like 'en_core_web_sm' because that will overwrite that model. You can read more here https://spacy.io/usage/saving-loading\n",
    "blank_nlp.to_disk('blank_nlp')\n",
    "full_nlp.to_disk('full_nlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Also while we are looking at those let's also download the larger spaCy English model\n",
    "# !python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open the meta.json in the `blank_nlp` folder we just created. It should look like this:\n",
    "![blank_nlp](./images/blank_nlp.png)\n",
    "\n",
    "This contains all the top-level information about our model. It's fairly sparse because this was our blank model, but towards the bottom you do see that this blank version contains our `entity_ruler` pipeline and our label of `PERSON`.\n",
    "\n",
    "Let's compare to the `full_nlp` folder!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a lot going on here so let's take a look at the spaCy documentation for the meta.json https://spacy.io/api/data-formats#meta. We can see that this contains information on how our model was trained (though since spacy 3.0 this file no longer specifies how it will be built)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full_nlp.pipe_names\n",
    "# full_nlp.pipe_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After clicking through the documentation, we can also click through the other folders. In `entity_ruler`, you'll find a list of all our patterns that we added to the model for example. You can also take a look inside of `vocab` that contains the `strings.json` file, which has a list of all the words that our model was trained on.\n",
    "\n",
    "Notice that in both our models our `meta.json` has the following setting under `vectors`:\n",
    "\n",
    "```python\n",
    "\"vectors\":{\n",
    "    \"width\":0,\n",
    "    \"vectors\":0,\n",
    "    \"keys\":0,\n",
    "    \"name\":null\n",
    "}\n",
    "```\n",
    "\n",
    "This is why we downloaded the large spaCy model, so let's save a version of it to disk (I will likely work locally for this since I doubt Github or Binder will appreciate a giant model üòÖ).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_nlp = spacy.load('en_core_web_lg')\n",
    "large_nlp.to_disk('large_nlp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the vectors now in our larger model. In our `meta.json`, we should now see the following:\n",
    "\n",
    "```python\n",
    "\"vectors\":{\n",
    "    \"width\":300,\n",
    "    \"vectors\":684830,\n",
    "    \"keys\":684830,\n",
    "    \"name\":\"en_vectors\"\n",
    "  }\n",
    "```\n",
    "From the documentation we can learn the following:\n",
    "> Information about the word vectors included with the pipeline. Typically a dict with the keys \"width\", \"vectors\" (number of vectors), \"keys\" and \"name\".\n",
    "Or visit the model documentation directly https://spacy.io/models/en#en_core_web_lg.\n",
    "\n",
    "To break this down more, what we are seeing is that in this model, we have a set of vectors named `en_vectors` (could have a different name depending on the model), that has identical number of keys and vectors, as well as a width of 300. Those keys and vectors are our tokens and their respective vector, while the width tells us that each word vector has 300 dimensions üò≥.\n",
    "\n",
    "For those unfamiliar, word vectors are essentially the backbone of modern machine learning.\n",
    "\n",
    "We can create word vectors by essentially representing the frequency of words in a corpus as counts. \n",
    "\n",
    "![vector](https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/assets/atap_0402.png)\n",
    "\n",
    "This image is from a great book, *Applied Text Analysis with Python* https://www.oreilly.com/library/view/applied-text-analysis/9781491963036/. But it's showing us how you would start build word counts into vectors.\n",
    "\n",
    "The main assumption about how language works here comes from John Firth, *Modes of *Meaning* 1957:\n",
    "\n",
    "![firth](https://image.slidesharecdn.com/icsc2012distributionalpp2-120920083125-phpapp01/95/a-study-on-compositional-semantics-of-words-in-distributional-spaces-2-728.jpg?cb=1348129993)\n",
    "\n",
    "Once we represent words as vectors we can start using vector math to explore how words cluster together (for more on distance metrics I would highly recommend this Programming Historian tutorial https://programminghistorian.org/en/lessons/common-similarity-measures#what-is-similarity-or-distance)\n",
    "\n",
    "![word_vectors](https://miro.medium.com/max/1838/1*OEmWDt4eztOcm5pr2QbxfA.png)\n",
    "\n",
    "These are some of the most famous examples of word vectors, and spaCy actually has functionality built in for you to try and find most_similar terms once we are using their vector models.\n",
    "\n",
    "For a more zoomed out explanation of what spaCy is doing, I highly recommend checking out these two stack overflow answers.\n",
    "\n",
    "https://stackoverflow.com/questions/60381170/which-deep-learning-algorithm-does-spacy-uses-when-we-train-custom-model/60394246#60394246\n",
    "\n",
    "\n",
    "https://stackoverflow.com/questions/44492430/how-does-spacy-use-word-embeddings-for-named-entity-recognition-ner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIME FOR A BREAK ‚òïÔ∏è\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Custom NER Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far we've started reviewing our homework, doing rules-based NER, and then understanding how spaCy works under the hood.\n",
    "\n",
    "In the remainder of our time, I want to spend some time discussing using non-English language models and training custom NER models. We may or may not get through everything today but let's see how it goes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could breakout into breakout rooms now to discuss multilingual NER by language or time-period. Or we can have a general discussion together.\n",
    "\n",
    "One thing I'm curious about is how many people are working with non-English data? Also how many have trained custom models before?\n",
    "\n",
    "I'll be honest here that none of my intro DH courses have been advanced enough to include lessons on custom NER models (though I have had students use it in independent seminar). One big question that I would like us to keep in mind is how does one decide if they want to build a custom model from scratch or if they want to fine-tune an existing model. \n",
    "\n",
    "Some of this tradeoff is technical, but a lot of it is also your personal project goals.\n",
    "\n",
    "Let's take a look first at using different language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that spaCy has quite a few language models already built-in https://spacy.io/usage/models#languages but I also know from Monday that some of you have already used `stanza` https://stanfordnlp.github.io/stanza/ner.html because of its language support.\n",
    "\n",
    "One of our goals from the homework was trying out a new NER library so let's briefly test out stanza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-30 12:23:31 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-06-30 12:23:31 INFO: Use device: cpu\n",
      "2021-06-30 12:23:31 INFO: Loading: tokenize\n",
      "2021-06-30 12:23:31 INFO: Loading: ner\n",
      "2021-06-30 12:23:32 INFO: Done loading processors!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entity: Professor McGonagall\ttype: PERSON\n"
     ]
    }
   ],
   "source": [
    "stanza_nlp = stanza.Pipeline(lang='en', processors='tokenize,ner')\n",
    "doc = stanza_nlp(films_df[0:1].Sentence.values[0])\n",
    "print(*[f'entity: {ent.text}\\ttype: {ent.type}' for ent in doc.ents], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly stanza is regonizing both McGonagall and Professor as a person from the outset, which spaCy was unable to do.\n",
    "\n",
    "Let's try running on our film dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS RUNS VERY SLOWLY!!!\n",
    "def find_stanza_entities(row):\n",
    "    # code goes here\n",
    "    stanza_sentence = stanza_nlp(row.Sentence)\n",
    "    \n",
    "    list_tokens = []\n",
    "    list_entities = []\n",
    "    for token in stanza_sentence.ents:\n",
    "        list_tokens.append(token.text)\n",
    "        list_entities.append(token.type)\n",
    "    row['stanza_tokens'] = list_tokens\n",
    "    row['stanza_entities'] = list_entities\n",
    "    return row\n",
    "films_stanza = films_df[0:20].apply(find_stanza_entities, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>movie_number</th>\n",
       "      <th>stanza_tokens</th>\n",
       "      <th>stanza_entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I should've known that you would be here, Prof...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Professor McGonagall]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Good evening, Professor Dumbledore.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[evening, Dumbledore]</td>\n",
       "      <td>[TIME, PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Are the rumors true, Albus?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Albus]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>I'm afraid so, professor.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>The good and the bad.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>And the boy?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Hagrid is bringing him.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Hagrid]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>Do you think it wise to trust Hagrid with some...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Hagrid]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Ah, Professor, I would trust Hagrid with my life.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Hagrid]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Professor Dumbledore, sir.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Dumbledore]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Professor McGonagall.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[McGonagall]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>No problems, I trust, Hagrid?</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Hagrid]</td>\n",
       "      <td>[PERSON]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Hagrid</td>\n",
       "      <td>No, sir.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Little tyke fell asleep just as we were flying...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[Bristol]</td>\n",
       "      <td>[GPE]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Hagrid</td>\n",
       "      <td>Try not to wake him.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hagrid</td>\n",
       "      <td>There you go.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Dumbledore</td>\n",
       "      <td>Albus, do you really think it's safe, leaving ...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>I've watched them all day.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>They're the worst sort of Muggles, imaginable.</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>McGonagall</td>\n",
       "      <td>They really are...</td>\n",
       "      <td>film 1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Character                                           Sentence  \\\n",
       "0   Dumbledore  I should've known that you would be here, Prof...   \n",
       "1   McGonagall                Good evening, Professor Dumbledore.   \n",
       "2   McGonagall                        Are the rumors true, Albus?   \n",
       "3   Dumbledore                          I'm afraid so, professor.   \n",
       "4   Dumbledore                              The good and the bad.   \n",
       "5   McGonagall                                       And the boy?   \n",
       "6   Dumbledore                            Hagrid is bringing him.   \n",
       "7   McGonagall  Do you think it wise to trust Hagrid with some...   \n",
       "8   Dumbledore  Ah, Professor, I would trust Hagrid with my life.   \n",
       "9       Hagrid                         Professor Dumbledore, sir.   \n",
       "10      Hagrid                              Professor McGonagall.   \n",
       "11  Dumbledore                      No problems, I trust, Hagrid?   \n",
       "12      Hagrid                                           No, sir.   \n",
       "13      Hagrid  Little tyke fell asleep just as we were flying...   \n",
       "14      Hagrid                               Try not to wake him.   \n",
       "15      Hagrid                                      There you go.   \n",
       "16  Dumbledore  Albus, do you really think it's safe, leaving ...   \n",
       "17  McGonagall                         I've watched them all day.   \n",
       "18  McGonagall     They're the worst sort of Muggles, imaginable.   \n",
       "19  McGonagall                                 They really are...   \n",
       "\n",
       "   movie_number           stanza_tokens stanza_entities  \n",
       "0        film 1  [Professor McGonagall]        [PERSON]  \n",
       "1        film 1   [evening, Dumbledore]  [TIME, PERSON]  \n",
       "2        film 1                 [Albus]        [PERSON]  \n",
       "3        film 1                      []              []  \n",
       "4        film 1                      []              []  \n",
       "5        film 1                      []              []  \n",
       "6        film 1                [Hagrid]        [PERSON]  \n",
       "7        film 1                [Hagrid]        [PERSON]  \n",
       "8        film 1                [Hagrid]        [PERSON]  \n",
       "9        film 1            [Dumbledore]        [PERSON]  \n",
       "10       film 1            [McGonagall]        [PERSON]  \n",
       "11       film 1                [Hagrid]        [PERSON]  \n",
       "12       film 1                      []              []  \n",
       "13       film 1               [Bristol]           [GPE]  \n",
       "14       film 1                      []              []  \n",
       "15       film 1                      []              []  \n",
       "16       film 1                      []              []  \n",
       "17       film 1                      []              []  \n",
       "18       film 1                      []              []  \n",
       "19       film 1                      []              []  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "films_stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these are very promising results, especially considering spaCy needed to have additional rules to identify these names, the stanza implementation is very slow and also requires learning a new syntax. While we can't fix the speed of the library, we can use stanza models with spaCy https://github.com/explosion/spacy-stanza so let's try that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install spacy_stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-06-30 12:23:41 INFO: Loading these models for language: en (English):\n",
      "=========================\n",
      "| Processor | Package   |\n",
      "-------------------------\n",
      "| tokenize  | combined  |\n",
      "| pos       | combined  |\n",
      "| lemma     | combined  |\n",
      "| depparse  | combined  |\n",
      "| sentiment | sstplus   |\n",
      "| ner       | ontonotes |\n",
      "=========================\n",
      "\n",
      "2021-06-30 12:23:41 INFO: Use device: cpu\n",
      "2021-06-30 12:23:41 INFO: Loading: tokenize\n",
      "2021-06-30 12:23:41 INFO: Loading: pos\n",
      "2021-06-30 12:23:41 INFO: Loading: lemma\n",
      "2021-06-30 12:23:41 INFO: Loading: depparse\n",
      "2021-06-30 12:23:41 INFO: Loading: sentiment\n",
      "2021-06-30 12:23:42 INFO: Loading: ner\n",
      "2021-06-30 12:23:43 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "import spacy_stanza\n",
    "\n",
    "spacy_stanza_nlp = spacy_stanza.load_pipeline(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/EZCorp/workspace/tapi_workshops/ner_hum/ner_hum_env/lib/python3.9/site-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ../c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "#STILL VERY SLOW!!\n",
    "def find_spacy_stanza_entities(row):\n",
    "    # code goes here\n",
    "    stanza_sentence = spacy_stanza_nlp(row.Sentence)\n",
    "    \n",
    "    list_tokens = []\n",
    "    list_entities = []\n",
    "    for token in stanza_sentence.ents:\n",
    "        list_tokens.append(token.text)\n",
    "        list_entities.append(token.label_)\n",
    "    row['stanza_tokens'] = list_tokens\n",
    "    row['stanza_entities'] = list_entities\n",
    "    return row\n",
    "films_stanza = films_df[0:20].apply(find_spacy_stanza_entities, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I did download both the French and English models for stanza so one thing we could do know is try and answer our second homework option, of working with French and English data.\n",
    "\n",
    "We could also compare between spaCy and stanza using our model evaluate code from above. But before we start evaluating, I want to discuss something called `The Bender Rule`.\n",
    "\n",
    "![bender_rule](./images/bender_rule.png)\n",
    "\n",
    "https://thegradient.pub/the-benderrule-on-naming-the-languages-we-study-and-why-it-matters/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### HOMEWORK REVIEW CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so hypothetically we've written the code above for our second homework option, let's now return to option one since we didn't quite finish it. \n",
    "\n",
    "Our final goal was to add in new entities! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Incantation</th>\n",
       "      <th>Type</th>\n",
       "      <th>Effect</th>\n",
       "      <th>Light</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Summoning Charm</td>\n",
       "      <td>Accio</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Summons an object</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age Line</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Charm</td>\n",
       "      <td>Prevents people above or below a certain age f...</td>\n",
       "      <td>Blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name Incantation   Type  \\\n",
       "0  Summoning Charm       Accio  Charm   \n",
       "1         Age Line     Unknown  Charm   \n",
       "\n",
       "                                              Effect Light  \n",
       "0                                  Summons an object  None  \n",
       "1  Prevents people above or below a certain age f...  Blue  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spells_df = pd.read_csv('./archive/Spells.csv', sep=\";\")\n",
    "spells_df[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first check that spells exist in our films dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_spells(row, column_name):\n",
    "    spells = spells_df[spells_df.Incantation.isna() == False].Incantation.unique().tolist()\n",
    "    spells = [spell for spell in spells if len(spell) > 1]\n",
    "    identified_spells = []\n",
    "    for spell in spells:\n",
    "        if spell in row[f'{column_name}']:\n",
    "            identified_spells.append(spell)\n",
    "    row['identified_spells'] = ', '.join(identified_spells) if len(identified_spells) > 0 else ''\n",
    "    return row\n",
    "\n",
    "hp_spells = hp_dfs[hp_dfs.dialog.isna() == False].apply(find_spells, column_name='dialog', axis=1)\n",
    "films_spells = films_df[films_df.Sentence.isna() == False].apply(find_spells, column_name='Sentence', axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so we have spells within our scripts! Our next step is to extract this data as training data. Let's adapt our code from above here.\n",
    "\n",
    "~~HOMEWORK FOR FRIDAY!~~ \n",
    "\n",
    "Originally I wanted us to extract training data as homework but there was an issue with the spells data and working with spaCy that we'll discuss in class on Friday.\n",
    "\n",
    "So Friday we'll figure out how to make our evaluation training dataset but with the `SPELL` label:\n",
    "```python\n",
    "evaluation_data =[(\"I should've known that you would be here, Professor McGonagall.\",\n",
    "  {'entities': [[52, 62, 'PERSON']]})]\n",
    "```\n",
    "You can also consult this blog post that we'll be following for training our custom model to see how our data needs to be formatted https://towardsdatascience.com/using-spacy-3-0-to-build-a-custom-ner-model-c9256bea098).\n",
    "\n",
    "If you have time before class, do read the spaCy docs on rules-based matching https://spacy.io/usage/rule-based-matching and then also try to working with multilingual data with the ParlaMint dataset (load in the data and try extracting entities with the different language models)."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "ner_hum_env",
   "language": "python",
   "name": "ner_hum_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}